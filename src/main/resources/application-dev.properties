# 只有下面三个是必填项（使用内嵌数据库的话这三个也可以不用填，会使用默认配置），其他配置不是必须的
spring.datasource.driverClassName = com.mysql.jdbc.Driver
spring.datasource.url = jdbc:mysql://localhost:3306/asksea?useUnicode=true&characterEncoding=UTF-8
spring.datasource.username = root
spring.datasource.password = 5231328yxf
#Druid 数据源配置，继承spring.datasource.* 配置，相同则覆盖
spring.datasource.druid.initial-size=2
spring.datasource.druid.max-active=30
spring.datasource.druid.min-idle=2
spring.datasource.druid.max-wait=1234
spring.datasource.druid.pool-prepared-statements=true
spring.datasource.druid.max-pool-prepared-statement-per-connection-size=5
#spring.datasource.druid.max-open-prepared-statements= #等价于上面的max-pool-prepared-statement-per-connection-size
spring.datasource.druid.validation-query=select 1
spring.datasource.druid.validation-query-timeout=1
spring.datasource.druid.test-on-borrow=true
spring.datasource.druid.test-on-return=true
spring.datasource.druid.test-while-idle=true
spring.datasource.druid.time-between-eviction-runs-millis=10000
spring.datasource.druid.min-evictable-idle-time-millis=30001
spring.datasource.druid.async-close-connection-enable=true
#mybatis
mybatis.type-aliases-package=cn.webyun.aistoaccumulokafka.domain
mybatis.configuration.map-underscore-to-camel-case=true


accumulo.instance.id = ais
accumulo.catalog = ais_data
accumulo.user=root
accumulo.password=ais
accumulo.zookeepers= 10.20.69.72:2181,10.20.69.73:2181,10.20.69.74:2181

kafka.brokers= 10.20.69.72:9092,10.20.69.73:9092,10.20.69.74:9092
kafka.zookeepers= 10.20.69.72:2181,10.20.69.73:2181,10.20.69.74:2181


#url api
api.getComKey=http://shipapi.chinaports.com/dataApi/getComKey
api.getPortShipbefore=http://shipapi.chinaports.com/dataApigetPortShipbefore/
api.getShipBasicInfo=http://shipapi.chinaports.com/shipDataApi/getShipBasicInfo
api.getShipHistorTrack=http://shipapi.chinaports.com/shipDataApi/getShipHistorTrack
